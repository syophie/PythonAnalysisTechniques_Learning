{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4304151a",
   "metadata": {},
   "source": [
    "Purpose: compare predictors of the Probit and Logit models from Python statsmodels.formula.api package\n",
    "- Full list of models avaliable: https://www.statsmodels.org/stable/api.html#statsmodels-formula-api\n",
    "\n",
    "Dataset - Spambase: compare predictors of Logiv vs Probit\n",
    "    #> Binary target: Spam vs. not spam\n",
    "    #> Why useful: Text‑derived numeric predictors; good for seeing how logit vs. probit behave with many predictors & correlated features.\n",
    "    #> Expectation: the curves for the two models will almost overlap. The difference will be the scaling on the coefficient.\n",
    "\n",
    "*Logit Model - Summarised:*\n",
    "\n",
    ">Logit assumes a logistic distribution (fatter tails, slightly flatter peak): \n",
    "- mean = 0 and Variance ≈ π²/3 = 3.29\n",
    "- Logit predicted probabilities spread slightly more into 0 and 1 because of heavier tails\n",
    "> Compared to Probit:\n",
    "- Logit is simplier and easier to interpret (odds ratios)\n",
    "- Industry standard\n",
    "-  Logit coefficients tend to be about 1.6× (≈ π/√3) larger than probit coefficients, as distribution have fatter tail ends\n",
    "\n",
    "*Probit Model - Summarised:*\n",
    "\n",
    ">Probit assumes a standard normal distribution (thinner tails, sharper peak): \n",
    "- Mean = 0 and Varaince = 1\n",
    "- Probit predicted probabilities tend to cluster more tightly around 0.5\n",
    "\n",
    ">For many behavioural, psychometric, and economic processes, it’s often more natural to assume the underlying propensity follows a normal distribution—making a probit specification conceptually cleaner.\n",
    "- reduces sensitivity to extreme values = Slightly more conservative estimates at extremes\n",
    "- Causal inference = probit is a typical model for propensity scores as model often aligns with normal distributional assumptions when estimating treatment assignment probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2f9e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up: import packages\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# Set up dummy data: Spambase\n",
    "url = \"https://raw.githubusercontent.com/readytensor/rt-datasets-binary-classification/main/datasets/processed/spambase/spambase.csv\"\n",
    "    #> from git Hub repository of datasets\n",
    "\n",
    "df_Spam = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5c8246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 59 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          4601 non-null   int64  \n",
      " 1   word_freq_make              4601 non-null   float64\n",
      " 2   word_freq_address           4601 non-null   float64\n",
      " 3   word_freq_all               4601 non-null   float64\n",
      " 4   word_freq_3d                4601 non-null   float64\n",
      " 5   word_freq_our               4601 non-null   float64\n",
      " 6   word_freq_over              4601 non-null   float64\n",
      " 7   word_freq_remove            4601 non-null   float64\n",
      " 8   word_freq_internet          4601 non-null   float64\n",
      " 9   word_freq_order             4601 non-null   float64\n",
      " 10  word_freq_mail              4601 non-null   float64\n",
      " 11  word_freq_receive           4601 non-null   float64\n",
      " 12  word_freq_will              4601 non-null   float64\n",
      " 13  word_freq_people            4601 non-null   float64\n",
      " 14  word_freq_report            4601 non-null   float64\n",
      " 15  word_freq_addresses         4601 non-null   float64\n",
      " 16  word_freq_free              4601 non-null   float64\n",
      " 17  word_freq_business          4601 non-null   float64\n",
      " 18  word_freq_email             4601 non-null   float64\n",
      " 19  word_freq_you               4601 non-null   float64\n",
      " 20  word_freq_credit            4601 non-null   float64\n",
      " 21  word_freq_your              4601 non-null   float64\n",
      " 22  word_freq_font              4601 non-null   float64\n",
      " 23  word_freq_000               4601 non-null   float64\n",
      " 24  word_freq_money             4601 non-null   float64\n",
      " 25  word_freq_hp                4601 non-null   float64\n",
      " 26  word_freq_hpl               4601 non-null   float64\n",
      " 27  word_freq_george            4601 non-null   float64\n",
      " 28  word_freq_650               4601 non-null   float64\n",
      " 29  word_freq_lab               4601 non-null   float64\n",
      " 30  word_freq_labs              4601 non-null   float64\n",
      " 31  word_freq_telnet            4601 non-null   float64\n",
      " 32  word_freq_857               4601 non-null   float64\n",
      " 33  word_freq_data              4601 non-null   float64\n",
      " 34  word_freq_415               4601 non-null   float64\n",
      " 35  word_freq_85                4601 non-null   float64\n",
      " 36  word_freq_technology        4601 non-null   float64\n",
      " 37  word_freq_1999              4601 non-null   float64\n",
      " 38  word_freq_parts             4601 non-null   float64\n",
      " 39  word_freq_pm                4601 non-null   float64\n",
      " 40  word_freq_direct            4601 non-null   float64\n",
      " 41  word_freq_cs                4601 non-null   float64\n",
      " 42  word_freq_meeting           4601 non-null   float64\n",
      " 43  word_freq_original          4601 non-null   float64\n",
      " 44  word_freq_project           4601 non-null   float64\n",
      " 45  word_freq_re                4601 non-null   float64\n",
      " 46  word_freq_edu               4601 non-null   float64\n",
      " 47  word_freq_table             4601 non-null   float64\n",
      " 48  word_freq_conference        4601 non-null   float64\n",
      " 49  char_freq_%3B               4601 non-null   float64\n",
      " 50  char_freq_%28               4601 non-null   float64\n",
      " 51  char_freq_%5B               4601 non-null   float64\n",
      " 52  char_freq_%21               4601 non-null   float64\n",
      " 53  char_freq_%24               4601 non-null   float64\n",
      " 54  char_freq_%23               4601 non-null   float64\n",
      " 55  capital_run_length_average  4601 non-null   float64\n",
      " 56  capital_run_length_longest  4601 non-null   int64  \n",
      " 57  capital_run_length_total    4601 non-null   int64  \n",
      " 58  class                       4601 non-null   int64  \n",
      "dtypes: float64(55), int64(4)\n",
      "memory usage: 2.1 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.int64(0), np.int64(0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive stats\n",
    "# Step 1: File shape, column names, dtypes, suspected mis‑types (IDs as numeric, categories as free text), duplicated rows/IDs.\n",
    "    #> Structure\n",
    "df_Spam.shape, df_Spam.columns.tolist()\n",
    "\n",
    "    #> Types and basic nulls\n",
    "df_Spam.info()\n",
    "\n",
    "    #> Duplicate rows / duplicate keys (adjust key list)\n",
    "dupe_rows = df_Spam.duplicated().sum()\n",
    "dupe_keys = df_Spam.duplicated(subset=[\"id\"]).sum() if \"id\" in df_Spam.columns else None\n",
    "dupe_rows, dupe_keys\n",
    "\n",
    "# Step 2: EDA specific to Probit / Logit requirements (binary target, class balance, feature distributions and scales, multicollinearity, outliers/influential points)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
